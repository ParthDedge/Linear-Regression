# ğŸ“Š Linear Regression Techniques in Machine Learning

This repository contains a comprehensive Jupyter Notebook exploring various **Linear Regression techniques** for regression analysis. The goal of this project is to understand and compare the performance of different linear models including Ordinary Linear Regression, Ridge Regression, Lasso Regression, and Elastic Net.

## ğŸš€ Overview

Linear regression is a fundamental algorithm in machine learning used for predictive modeling. In this notebook, we:

- Build and train models using multiple linear regression techniques.
- Evaluate model performance using **Root Mean Squared Error (RMSE)** and **RÂ² Score**.
- Tune hyperparameters using **GridSearchCV** for optimal performance.
- Compare results across various models on training and testing datasets.

---

## ğŸ§  Techniques Covered

- âœ… Linear Regression  
- âœ… Ridge Regression (with GridSearchCV for optimal alpha)  
- âœ… Lasso Regression (with GridSearchCV)  
- âœ… Elastic Net Regression

---

## ğŸ“ˆ Evaluation Metrics Summary

| Model              | Train RMSE | Train RÂ² | Test RMSE | Test RÂ²  |
|--------------------|------------|----------|-----------|----------|
| **Linear Regression** | 9.775     | 0.985    | 10.538    | 0.982    |
| **Ridge Regression**  | 9.777     | 0.985    | 10.544    | 0.982    |
| **Lasso Regression**  | 9.775     | 0.985    | 10.539    | 0.982    |
| **Elastic Net**       | 9.782     | 0.985    | 10.555    | 0.982    |

All models performed well, with RÂ² scores above **98%**, demonstrating that linear models can be powerful tools when applied appropriately to well-prepared data.

---

## ğŸ“‚ Repository Contents

- `linear_regression_techniques.ipynb` â€“ Jupyter notebook containing all implementations
- `README.md` â€“ Project documentation and explanation

---

## ğŸ› ï¸ Tools & Libraries

- Python  
- Pandas, NumPy  
- Matplotlib, Seaborn  
- Scikit-learn (LinearRegression, Ridge, Lasso, ElasticNet, GridSearchCV)

---
